{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massaging to Improve Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "Categorical Features: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, accuracy_score, classification_report, recall_score, f1_score\n",
    "\n",
    "# Import files for Fairness Metrics\n",
    "from individual_fairness import eval_ind_fairness \n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(\"..\", \"data\", \"income\", \"adult.data\") # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define column names\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "                'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "                'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Assign column names to the DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Divide the features into numerical and non-numerical lists\n",
    "# Extract numerical and string features\n",
    "num_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_features = df.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Features: {num_features}\")\n",
    "print(f\"Categorical Features: {cat_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert income column to binary, flag errors\n",
    "def convert_income(value):\n",
    "    value = str(value).strip()\n",
    "    if value == '>50K':\n",
    "        return 1\n",
    "    elif value == '<=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan  # Flag invalid values as NaN (or set a custom error flag)\n",
    "\n",
    "df['income'] = df['income'].apply(convert_income)\n",
    "\n",
    "# Encode the sex based on privileged/underprivileged\n",
    "def encode_sex(value):\n",
    "    value = str(value).strip()\n",
    "    if value == \"Male\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  \n",
    "\n",
    "df['sex'] = df['sex'].apply(encode_sex)\n",
    "\n",
    "# Identify and display rows with errors\n",
    "error_rows = df[df['income'].isna()]\n",
    "if not error_rows.empty:\n",
    "    print(\"Invalid income values found in \", error_rows.size, \"rows: \")\n",
    "    print(error_rows)\n",
    "\n",
    "cat_features.remove('sex')\n",
    "cat_features.remove('income')\n",
    "\n",
    "# Initialize OneHotEncoder for remaining categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' for avoiding multicollinearity\n",
    "\n",
    "# Fit and transform\n",
    "encoded_array = encoder.fit_transform(df[cat_features])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(cat_features))\n",
    "\n",
    "# Concatenate with original DataFrame (excluding original categorical columns)\n",
    "df = pd.concat([df.drop(columns=cat_features), encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_performance(y_test, y_pred):\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Display metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masaging to Remove Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discrimination(df, sensitive_attr, class_attr, privileged_value, positive_class):\n",
    "    # Compute the discrimination score (difference in positive outcome rates).\n",
    "    privileged = df[df[sensitive_attr] == privileged_value]\n",
    "    unprivileged = df[df[sensitive_attr] != privileged_value]\n",
    "\n",
    "    pos_rate_privileged = sum(privileged[class_attr] == positive_class) / len(privileged)\n",
    "    pos_rate_unprivileged = sum(unprivileged[class_attr] == positive_class) / len(unprivileged)\n",
    "\n",
    "    return pos_rate_unprivileged - pos_rate_privileged\n",
    "\n",
    "def compute_m(df, sensitive_attr, class_attr, privileged_value, positive_class):\n",
    "    # Compute number of instances M to relabel.\n",
    "    disc = compute_discrimination(df, sensitive_attr, class_attr, privileged_value, positive_class)\n",
    "    \n",
    "    n_privileged = len(df[df[sensitive_attr] == privileged_value])\n",
    "    n_unprivileged = len(df[df[sensitive_attr] != privileged_value])\n",
    "    \n",
    "    return int(abs(disc) * (n_privileged * n_unprivileged) / len(df))\n",
    "\n",
    "def rank_instances(df, features, sensitive_attr, class_attr):\n",
    "    # Train a classifier to rank instances by likelihood of being positive.\n",
    "    X = df[features]\n",
    "    y = df[class_attr]\n",
    "\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    scores = model.predict_proba(X)[:, 1]  # Probability of positive class\n",
    "    df['score'] = scores\n",
    "    return df\n",
    "\n",
    "def apply_massaging(df, sensitive_attr, class_attr, privileged_value, positive_class):\n",
    "    # Perform massaging technique.\n",
    "    # Step 1: Compute M\n",
    "    M = compute_m(df, sensitive_attr, class_attr, privileged_value, positive_class)\n",
    "    print(f\"Number of label changes (M): {M}\")\n",
    "\n",
    "    if M == 0:\n",
    "        print(\"No massaging needed.\")\n",
    "        return df\n",
    "\n",
    "    # Step 2: Rank instances\n",
    "    features = [col for col in df.columns if col not in [sensitive_attr, class_attr]]\n",
    "    df = rank_instances(df, features, sensitive_attr, class_attr)\n",
    "\n",
    "    # Step 3: Modify labels\n",
    "    unprivileged_neg = df[(df[sensitive_attr] != privileged_value) & (df[class_attr] != positive_class)]\n",
    "    privileged_pos = df[(df[sensitive_attr] == privileged_value) & (df[class_attr] == positive_class)]\n",
    "\n",
    "    # Promote top M from unprivileged_neg\n",
    "    df.loc[unprivileged_neg.nlargest(M, 'score').index, class_attr] = positive_class\n",
    "\n",
    "    # Demote bottom M from privileged_pos\n",
    "    df.loc[privileged_pos.nsmallest(M, 'score').index, class_attr] = 1 - positive_class\n",
    "\n",
    "    # Drop the ranking column\n",
    "    df.drop(columns=['score'], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8618\n",
      "Precision: 0.7634\n",
      "Recall: 0.6173\n",
      "F1 Score: 0.6827\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      4944\n",
      "           1       0.76      0.62      0.68      1568\n",
      "\n",
      "    accuracy                           0.86      6512\n",
      "   macro avg       0.82      0.78      0.80      6512\n",
      "weighted avg       0.86      0.86      0.86      6512\n",
      "\n",
      "Individual Fairness For Baseline: 0.8263\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "# Create a pipeline with logistic regression\n",
    "model = Pipeline([\n",
    "    ('preprocessor', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance of baseline model\n",
    "eval_performance(y_test, y_pred)\n",
    "\n",
    "# Evaluate Individual Fairness\n",
    "ind_fairness = eval_ind_fairness(X_train, y_train, X_test, y_pred)\n",
    "print(f'Individual Fairness For Baseline: {ind_fairness:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance After Massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label changes (M): 1414\n",
      "Accuracy: 0.8019\n",
      "Precision: 0.6695\n",
      "Recall: 0.3501\n",
      "F1 Score: 0.4598\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4944\n",
      "           1       0.67      0.35      0.46      1568\n",
      "\n",
      "    accuracy                           0.80      6512\n",
      "   macro avg       0.75      0.65      0.67      6512\n",
      "weighted avg       0.78      0.80      0.78      6512\n",
      "\n",
      "Individual Fairness Ater Massaging: 0.7974\n"
     ]
    }
   ],
   "source": [
    "# Apply massaging technique\n",
    "df_massaged = apply_massaging(df, 'sex', 'income', privileged_value=1, positive_class=1)\n",
    "\n",
    "X_massaged = df_massaged.drop(columns=['income'])\n",
    "y_massaged = df_massaged['income']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_massaged, y_massaged, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance of baseline model\n",
    "eval_performance(y_test, y_pred)\n",
    "\n",
    "# Evaluate Individual Fairness\n",
    "ind_fairness_massaged = eval_ind_fairness(X_train, y_train, X_test, y_pred)\n",
    "print(f'Individual Fairness Ater Massaging: {ind_fairness_massaged:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
