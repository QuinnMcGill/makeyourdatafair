{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4081b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "BEFORE SUPPRESSION (ORIGINAL DATA)\n",
      "========================================\n",
      "\n",
      "Dataset Fairness Metrics (Original):\n",
      "Statistical Parity Difference: -0.1963\n",
      "Disparate Impact: 0.3580\n",
      "\n",
      "Model Performance (Original):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      4976\n",
      "           1       0.72      0.58      0.64      1537\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.80      0.76      0.77      6513\n",
      "weighted avg       0.84      0.85      0.84      6513\n",
      "\n",
      "\n",
      "Model Fairness Metrics (Original):\n",
      "Equal Opportunity Difference: -0.0777\n",
      "Average Odds Difference: -0.0781\n",
      "Disparate Impact (Predictions): 0.3051\n",
      "\n",
      "========================================\n",
      "AFTER SUPPRESSION (REMOVED 'sex' ATTRIBUTE)\n",
      "========================================\n",
      "\n",
      "Note: Dataset fairness metrics unavailable after suppression (protected attribute removed)\n",
      "\n",
      "Model Performance (After Suppression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      4976\n",
      "           1       0.72      0.58      0.64      1537\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.80      0.76      0.77      6513\n",
      "weighted avg       0.84      0.85      0.84      6513\n",
      "\n",
      "\n",
      "Model Fairness Metrics (After Suppression):\n",
      "Equal Opportunity Difference: -0.0777\n",
      "Average Odds Difference: -0.0781\n",
      "Disparate Impact (Predictions): 0.3051\n",
      "\n",
      "========================================\n",
      "IMPROVEMENT COMPARISON\n",
      "========================================\n",
      "\n",
      "Model Fairness Improvement:\n",
      "Equal Opportunity Difference: +0.0000 (Before: -0.0777, After: -0.0777)\n",
      "Average Odds Difference: +0.0000 (Before: -0.0781, After: -0.0781)\n",
      "Disparate Impact (Predictions): +0.0000 (Before: 0.3051, After: 0.3051)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "# 1. Load and Prepare Data (unchanged)\n",
    "def load_data():\n",
    "    import kagglehub\n",
    "    path = kagglehub.dataset_download(\"uciml/adult-census-income\")\n",
    "    df = pd.read_csv(path + '/adult.csv')\n",
    "    df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "                 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "    \n",
    "    # Convert target and protected attribute\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "    df['sex'] = df['sex'].map({'Female': 0, 'Male': 1})\n",
    "    \n",
    "    # Convert other categorical columns to numerical codes\n",
    "    categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                       'relationship', 'race', 'native-country']\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# 2. SUPPRESSION Preprocessing (NEW)\n",
    "def suppression_preprocessing(df, protected_attr):\n",
    "    \"\"\"Remove the protected attribute column entirely.\"\"\"\n",
    "    return df.drop(columns=[protected_attr])\n",
    "\n",
    "# 3. Fairness Evaluation Utilities (unchanged)\n",
    "def evaluate_dataset_fairness(df, target, protected_attr):\n",
    "    \"\"\"Evaluate fairness at dataset level (before/after suppression)\"\"\"\n",
    "    dataset = BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=[target],\n",
    "        protected_attribute_names=[protected_attr]\n",
    "    )\n",
    "    metric = BinaryLabelDatasetMetric(\n",
    "        dataset,\n",
    "        unprivileged_groups=[{protected_attr: 0}],  # Female\n",
    "        privileged_groups=[{protected_attr: 1}]      # Male\n",
    "    )\n",
    "    return {\n",
    "        'Statistical Parity Difference': metric.statistical_parity_difference(),\n",
    "        'Disparate Impact': metric.disparate_impact()\n",
    "    }\n",
    "\n",
    "def evaluate_model_fairness(y_true, y_pred, protected_attr):\n",
    "    \"\"\"Evaluate fairness of model predictions\"\"\"\n",
    "    dataset_true = BinaryLabelDataset(\n",
    "        df=pd.DataFrame({'y_true': y_true, 'protected': protected_attr}),\n",
    "        label_names=['y_true'],\n",
    "        protected_attribute_names=['protected']\n",
    "    )\n",
    "    dataset_pred = dataset_true.copy()\n",
    "    dataset_pred.labels = y_pred.reshape(-1, 1)\n",
    "    \n",
    "    metric = ClassificationMetric(\n",
    "        dataset_true,\n",
    "        dataset_pred,\n",
    "        unprivileged_groups=[{'protected': 0}],  # Female\n",
    "        privileged_groups=[{'protected': 1}]      # Male\n",
    "    )\n",
    "    return {\n",
    "        'Equal Opportunity Difference': metric.equal_opportunity_difference(),\n",
    "        'Average Odds Difference': metric.average_odds_difference(),\n",
    "        'Disparate Impact (Predictions)': BinaryLabelDatasetMetric(\n",
    "            dataset_pred,\n",
    "            unprivileged_groups=[{'protected': 0}],\n",
    "            privileged_groups=[{'protected': 1}]\n",
    "        ).disparate_impact()\n",
    "    }\n",
    "\n",
    "# 4. Main Pipeline (modified for suppression)\n",
    "def main():\n",
    "    # Load data\n",
    "    df = load_data()\n",
    "    \n",
    "    # =================================================================\n",
    "    # BEFORE SUPPRESSION (Original Data)\n",
    "    # =================================================================\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"BEFORE SUPPRESSION (ORIGINAL DATA)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Evaluate original dataset fairness\n",
    "    orig_fairness = evaluate_dataset_fairness(df, 'income', 'sex')\n",
    "    print(\"\\nDataset Fairness Metrics (Original):\")\n",
    "    for metric, value in orig_fairness.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Train model on original data\n",
    "    X_orig = df.drop(columns=['income', 'fnlwgt'])\n",
    "    y_orig = df['income']\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "        X_orig, y_orig, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), \n",
    "         ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country'])\n",
    "    ])\n",
    "    \n",
    "    model_orig = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    model_orig.fit(X_train_orig, y_train_orig)\n",
    "    \n",
    "    # Evaluate original model\n",
    "    y_pred_orig = model_orig.predict(X_test_orig)\n",
    "    print(\"\\nModel Performance (Original):\")\n",
    "    print(classification_report(y_test_orig, y_pred_orig))\n",
    "    \n",
    "    orig_model_fairness = evaluate_model_fairness(y_test_orig, y_pred_orig, X_test_orig['sex'])\n",
    "    print(\"\\nModel Fairness Metrics (Original):\")\n",
    "    for metric, value in orig_model_fairness.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # =================================================================\n",
    "    # AFTER SUPPRESSION\n",
    "    # =================================================================\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"AFTER SUPPRESSION (REMOVED 'sex' ATTRIBUTE)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Apply suppression\n",
    "    df_suppressed = suppression_preprocessing(df, 'sex')\n",
    "    \n",
    "    # Note: Can't calculate dataset fairness metrics after suppression (no 'sex' column)\n",
    "    print(\"\\nNote: Dataset fairness metrics unavailable after suppression (protected attribute removed)\")\n",
    "    \n",
    "    # Train model on suppressed data\n",
    "    X_suppressed = df_suppressed.drop(columns=['income', 'fnlwgt'])\n",
    "    y_suppressed = df_suppressed['income']\n",
    "    X_train_suppressed, X_test_suppressed, y_train_suppressed, y_test_suppressed = train_test_split(\n",
    "        X_suppressed, y_suppressed, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Update preprocessor to exclude 'sex'\n",
    "    preprocessor_suppressed = ColumnTransformer([\n",
    "        ('num', StandardScaler(), ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), \n",
    "         ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country'])\n",
    "    ])\n",
    "    \n",
    "    model_suppressed = Pipeline([\n",
    "        ('preprocessor', preprocessor_suppressed),\n",
    "        ('classifier', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    model_suppressed.fit(X_train_suppressed, y_train_suppressed)\n",
    "    \n",
    "    # Evaluate suppressed model\n",
    "    y_pred_suppressed = model_suppressed.predict(X_test_suppressed)\n",
    "    print(\"\\nModel Performance (After Suppression):\")\n",
    "    print(classification_report(y_test_suppressed, y_pred_suppressed))\n",
    "    \n",
    "    # Need original test set's 'sex' for fairness evaluation\n",
    "    # We'll use X_test_orig['sex'] since train_test_split was done with same random_state\n",
    "    suppressed_model_fairness = evaluate_model_fairness(y_test_suppressed, y_pred_suppressed, X_test_orig['sex'])\n",
    "    print(\"\\nModel Fairness Metrics (After Suppression):\")\n",
    "    for metric, value in suppressed_model_fairness.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # =================================================================\n",
    "    # IMPROVEMENT COMPARISON\n",
    "    # =================================================================\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"IMPROVEMENT COMPARISON\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(\"\\nModel Fairness Improvement:\")\n",
    "    for metric in orig_model_fairness:\n",
    "        improvement = suppressed_model_fairness[metric] - orig_model_fairness[metric]\n",
    "        print(f\"{metric}: {improvement:+.4f} (Before: {orig_model_fairness[metric]:.4f}, After: {suppressed_model_fairness[metric]:.4f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
